{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b81396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is used to process the data output form the “StockSOC_ExtractPoints” script. \n",
    "# For each date where point data could be extracted from Sentinel imagery this script will \n",
    "# determine the features (variables) that produce a linear regression with the best R2 value. \n",
    "# You can specify the minimum and maximum number of features that are tested. Increasing the \n",
    "# maximum number of features to four or higher requires significantly more processing time. Using \n",
    "# leave-one-out cross validation with the best linear model, the following metrics \n",
    "# are calculated and writen to a CSV file that is output at the end of the script: \n",
    "# R square, Adjusted R square, RMSE, and normalized RMSE. Processing progress can be monitored \n",
    "# by viewing the metrics for each date after that date has been processed.\n",
    "\n",
    "# This script was written by Ned Horning [ned.horning@regen.network]\n",
    "\n",
    "# This script is free software; you can redistribute it and/or modify it under the\n",
    "# terms of the Apache License 2.0 License.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcccbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import geopandas as gpd \n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import sqrt \n",
    "from numpy import mean \n",
    "from numpy import absolute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9747255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enter input file from \"StockSOC_ExtractPoints\" and output CSV file paths and names ###\n",
    "inPickle = \"\"\n",
    "outCSV = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df039c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the attribute labels from the input tabular data for SOC, BD, and the point name ###\n",
    "# The attribute labels are the same as the attribute names in the point location ESRI Shapefile\n",
    "SOC = 'C%'  # Attribute name for soil carbon metric \n",
    "BD = 'BD'   # Attribute name for bulk density\n",
    "PointLabel = 'MUESTRA'   # Attribute name for point labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62aa4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specify the minimum and maximum number of features to use for testing best fit ###\n",
    "min_feat=2\n",
    "max_feat=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process stock. To process SOC change to False ###\n",
    "processStock = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54998a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calcualte normalized difference vegetation index\n",
    "def calcNDVI(red, nir):\n",
    "    return pd.DataFrame((nir - red)/(nir + red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calcualte soil-adjusted total vegetation index\n",
    "def calcSATVI(red, swir1, swir2):\n",
    "    return pd.DataFrame(((swir1 -red)/(swir1 + red+0.5)) * 1.5 - (swir2/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ff525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calcualte normalized burn ratio 2\n",
    "def calcNBR2(swir1, swir2):\n",
    "    return pd.DataFrame((swir1 -swir2)/(swir1 + swir2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af783849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calcualte soil organic carbon index\n",
    "def calcSOCI(blue, green, red):\n",
    "    return pd.DataFrame(blue/(red * green))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a9554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calcualte bare soil index\n",
    "def calcBSI(blue, red, nir, swir1):\n",
    "    return pd.DataFrame((swir1 + red) -(nir + blue) / (swir1 + red) + (nir + blue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fad1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calcualte adjusted R2\n",
    "def adjust_r2(r2, num_examples, num_features):\n",
    "    coef = (num_examples - 1) / (num_examples - num_features - 1) \n",
    "    return 1 - (1 - r2) * coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the tabular data that was output from StockSOC_ExtractPoints\n",
    "with open(inPickle, 'rb') as f:\n",
    "    pointsDFs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f47883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize for tabular data to be output to CSV\n",
    "regResults = pd.DataFrame(columns = ['Date', 'R2', 'Adjusted_R2', 'RMSE', 'BestFeatures'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a3c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dictionary of tabular one date at a time to find the set of variables\n",
    "# that gievs the lowest R2 value\n",
    "for iteration, key in enumerate(pointsDFs):\n",
    "    points = pointsDFs[key]\n",
    "    if (points['B3'].isna().sum() / len(points.index) < 0.2): # If under 20% of the values are NA (cloud masked)\n",
    "        print(\"Processing \" + key + \": \" + (str(len(pointsDFs.keys())-iteration-1)) + \n",
    "              \" images to go      \", end = \"\\r\")\n",
    "        points.dropna(inplace=True)\n",
    "        points['ndvi']= calcNDVI(points['B4'].astype(float), points['B8'].astype(float))\n",
    "        points['satvi']= calcSATVI(points['B4'].astype(float), points['B11'].astype(float), \n",
    "                                   points['B12'].astype(float))\n",
    "        points['nbr2']= calcNBR2(points['B11'].astype(float), points['B12'].astype(float))\n",
    "        points['soci']= calcSOCI(points['B2'].astype(float), points['B3'].astype(float), \n",
    "                                 points['B4'].astype(float))\n",
    "        points['bsi']= calcBSI(points['B2'].astype(float), points['B4'].astype(float), \n",
    "                                 points['B8'].astype(float), points['B11'].astype(float))\n",
    "\n",
    "        x = pd.DataFrame(points.drop([SOC, BD, PointLabel, 'stock'], axis=1))\n",
    "        if (processStock):\n",
    "            y = points[['stock']]\n",
    "        else:\n",
    "            y = points[[SOC]]\n",
    "        # Set up for leave one out processig\n",
    "        loo = LeaveOneOut()\n",
    "        # Set up for linear regression model\n",
    "        regr = linear_model.LinearRegression()\n",
    "        # Execute exhaustive feature selection algorithm\n",
    "        efs = EFS(regr, \n",
    "            min_features=min_feat,\n",
    "            max_features=max_feat,\n",
    "            scoring='r2',\n",
    "            cv=math.floor(len(points.index)/2))\n",
    "        efs.fit(x, y)\n",
    "        # Calculate adjusted R2\n",
    "        for i in efs.subsets_:\n",
    "            efs.subsets_[i]['adjusted_avg_score'] = (\n",
    "            adjust_r2(r2=efs.subsets_[i]['avg_score'],\n",
    "                  num_examples=x.shape[0]/10,\n",
    "                  num_features=len(efs.subsets_[i]['feature_idx']))\n",
    "            )\n",
    "        score = -99e10\n",
    "        # Select the best adjusted R2\n",
    "        for i in efs.subsets_:\n",
    "            score = efs.subsets_[i]['adjusted_avg_score']\n",
    "            if ( efs.subsets_[i]['adjusted_avg_score'] == score and\n",
    "                len(efs.subsets_[i]['feature_idx']) < len(efs.best_idx_) )\\\n",
    "              or efs.subsets_[i]['adjusted_avg_score'] > score:\n",
    "                efs.best_idx_ = efs.subsets_[i]['feature_idx']\n",
    "\n",
    "        print('Best subset:', efs.best_feature_names_)\n",
    "        x = points[list(efs.best_feature_names_)]\n",
    "        if (processStock):\n",
    "            y = points[['stock']]\n",
    "        else:\n",
    "            y = points[[SOC]]\n",
    "        \n",
    "        # Get the R2 Adjusted R2, RMSE and Normalize RMSE for the variable with the best fit\n",
    "        regr = linear_model.LinearRegression()\n",
    "        fitTOC = regr.fit(x, y)\n",
    "        R2TOC = fitTOC.score(x,y)\n",
    "        Adjusted_R2 = 1 - (1-fitTOC.score(x, y))*(len(y)-1)/(len(y)-x.shape[1]-1)\n",
    "        \n",
    "        # Calculate RMSE and Normalized RMSE using leave one out cross validation\n",
    "        cv = LeaveOneOut()\n",
    "        scores = cross_val_score(regr, x, y, scoring='neg_mean_squared_error',\n",
    "                         cv=cv, n_jobs=-1)\n",
    "        RMSE = sqrt(mean(absolute(scores)))\n",
    "        NRMSE = RMSE/list(y.mean())[0]\n",
    "        \n",
    "        # Print values to monitor processing\n",
    "        print('R2 score: {:.2f}'.format(R2TOC))\n",
    "        print('Adjusted R2 score: {:.2f}'.format(Adjusted_R2))\n",
    "        print('RMSE: {:.2f}'.format(RMSE))\n",
    "        print('NRMSE: {:.2f}'.format(NRMSE))\n",
    "        \n",
    "        # Append results to the table that will be outupt as a CSV file\n",
    "        regResults = regResults.append({'Date' : key, 'R2' : R2TOC, 'Adjusted_R2' : Adjusted_R2, \n",
    "                                        'RMSE' : RMSE, 'NRMSE' : NRMSE, 'BestFeatures' : efs.best_feature_names_, \n",
    "                                        'Intercept' : fitTOC.intercept_, 'Coefficients' : fitTOC.coef_}, \n",
    "                                       ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output tabular data to CSV file\n",
    "regResults.to_csv(outCSV, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
